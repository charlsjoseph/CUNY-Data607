shuffledDF <- dataset[sample(1:nrow(dataset)),]
nrow(shuffledDF)
colnames(shuffledDF)
# Creating the Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.98)
dataset = as.data.frame(as.matrix(dtm))
dataset$class = mergeDataSet$class
spamDF <- dataset %>% filter(`class` == "1" )
nrow(spamDF)
hamDF <- dataset %>% filter(`class` == "0" )
nrow(hamDF)
head(dataset$class)
nrow(dataset)
spam_word_frequency <- colSums(spamDF)
spam_word_frequency <- sort(spam_word_frequency, decreasing = TRUE)
spam_word_frequency[1:20]
spam_words <- names(spam_word_frequency)
wordcloud(spam_words[1:50], spam_word_frequency[1:50])
ham_word_frequency <- colSums(hamDF)
ham_word_frequency <- sort(ham_word_frequency, decreasing = TRUE)
ham_word_frequency[1:20]
ham_words <- names(ham_word_frequency)
wordcloud(ham_words[1:50], ham_word_frequency[1:50])
shuffledDF <- dataset[sample(1:nrow(dataset)),]
nrow(shuffledDF)
colnames(shuffledDF)
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(shuffledDF$class, SplitRatio = 0.8)
training_set = subset(shuffledDF, split == TRUE)
test_set = subset(shuffledDF, split == FALSE)
nrow(training_set)
nrow(test_set)
no_observation <- ncol(training_set) - 1
no_observation
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$class,
ntree = 10)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
nrow(subset(test_set, class == 0))
# Making the Confusion Matrix
cm = table(test_set[, no_observation], y_pred)
cm
no_observation <- ncol(training_set) - 1
no_observation
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$class,
ntree = 10)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
nrow(subset(test_set, class == 0))
# Making the Confusion Matrix
cm = table(test_set[, no_observation], y_pred)
cm
cm = table(test_set[, no_observation], y_pred)
cm
test_set$class
cm
table(y_pred>0,test_set[class])
table(y_pred>0,test_set$class)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$class,
ntree = 10)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$class)
#library(readtext)
#library(dplyr)
# install.packages("readtext")
#install.packages("wordcloud")
library(wordcloud)
library(dplyr)
library(readtext)
library(stringr)
dir="C:/Users/Charls/Documents/CunyMSDS/607-Data Acquiction/project-4/dataset/spam/"
filename = list.files(dir)
# get_email_body <- function(email){
#   email_body <- str_split(email,"\n\n") %>% lapply('[[',2) %>% unlist()
#   return(email_body)
# }
get_email_body <- function(emailContent){
msge <- str_split(emailContent,"\n\n") %>% unlist()
body <- paste(msge[2:length(msge)], collapse=' ' )
return(body)
}
#  filepath = "C:/Users/Charls/Documents/CunyMSDS/607-Data Acquiction/project-4/dataset/spam/00001.7848dde101aa985090474a91ec93fcf0"
#
# emailContent1 <-readtext(filepath)
# # email_body <- str_split(emailContent1,"\n\n") unlist()
#
# msg <- get_email_body(emailContent1)
#   msg <- gsub("<.*?>", " ", msg)
# msg
msgContent<-NA
for(i in 1:length(filename))
{
filepath<-paste0(dir,filename[i])
emailContent <-readtext(filepath)
msg <- get_email_body(emailContent)
msg <- gsub("<.*?>", " ", msg)
eachMsg<- list(paste(msg, collapse="\n"))
msgContent = c(msgContent,eachMsg)
}
spam<-data.frame()
spam<-as.data.frame(unlist(msgContent),stringsAsFactors = FALSE)
spam$class<-1
colnames(spam)<-c("msg","class")
head(spam)
nrow(spam)
dir="C:/Users/Charls/Documents/CunyMSDS/607-Data Acquiction/project-4/dataset/easy_ham/"
filename = list.files(dir)
msgContent<-NA
for(i in 1:length(filename))
{
filepath<-paste0(dir,filename[i])
emailContent <-readtext(filepath)
msg <- get_email_body(emailContent)
msg <- gsub("<.*?>", " ", msg)
eachMsg<- list(paste(msg, collapse="\n"))
msgContent = c(msgContent,eachMsg)
}
ham<-data.frame()
ham<-as.data.frame(unlist(msgContent),stringsAsFactors = FALSE)
ham$class<-0
colnames(ham)<-c("msg","class")
head(ham)
nrow(ham)
mergeDataSet<-rbind(spam,ham)
nrow(mergeDataSet)
#install.packages(c("tm", "SnowballC"))
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(mergeDataSet$msg))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
# Creating the Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.98)
dataset = as.data.frame(as.matrix(dtm))
dataset$outputType = mergeDataSet$class
spamDF <- dataset %>% filter(`class` == "1" )
# Creating the Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.98)
dataset = as.data.frame(as.matrix(dtm))
dataset$outputType = mergeDataSet$class
spamDF <- dataset %>% filter(`outputType` == "1" )
nrow(spamDF)
hamDF <- dataset %>% filter(`outputType` == "0" )
nrow(hamDF)
head(dataset$class)
nrow(dataset)
head(dataset$outputType)
spam_word_frequency <- colSums(spamDF)
spam_word_frequency <- sort(spam_word_frequency, decreasing = TRUE)
spam_word_frequency[1:20]
spam_words <- names(spam_word_frequency)
wordcloud(spam_words[1:50], spam_word_frequency[1:50])
ham_word_frequency <- colSums(hamDF)
ham_word_frequency <- sort(ham_word_frequency, decreasing = TRUE)
ham_word_frequency[1:20]
ham_words <- names(ham_word_frequency)
wordcloud(ham_words[1:50], ham_word_frequency[1:50])
shuffledDF <- dataset[sample(1:nrow(dataset)),]
nrow(shuffledDF)
colnames(shuffledDF)
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(shuffledDF$outputType, SplitRatio = 0.8)
training_set = subset(shuffledDF, split == TRUE)
test_set = subset(shuffledDF, split == FALSE)
nrow(training_set)
nrow(test_set)
no_observation <- ncol(training_set) - 1
no_observation
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 10)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
training_set$outputType
training_set$outputType %>% distinct()
training_set$outputType %>% as.character() %>% distinct()
training_set$outputType %>% as.numeric() %>% distinct()
training_set %>% filter(outputType != '0' ||outputType != '1' ) %>% distinct()
nrow(training_set)
training_set %>% filter(outputType != '0' ||outputType != '1' ) %>% distinct() %>% select("outputType")
nrow(training_set)
training_set %>% filter(outputType != '0' && outputType != '1' ) %>% distinct() %>% select("outputType")
accuracy <- 590/600 * 100
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 10)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 10)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 15)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 5)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 3)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 3)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 3)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 3)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 3)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
table(y_pred<0,test_set$outputType)
table(y_pred>0,test_set$outputType)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 3)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
table(y_pred>0,test_set$outputType)
accuracy <- 590/600 * 100
accuracy
nrow(y_pred>0)
length(y_pred>0)
length(y_pred[y_pred>0])
table(y_pred>0,test_set$outputType)
length(y_pred[y_pred>0])
table(y_pred>0,test_set$outputType)
table(y_pred,test_set$outputType)
table(y_pred>0,test_set$outputType)
table(y_pred,test_set$outputType)
>0
table(y_pred>0,test_set$outputType)
cm <- table(y_pred>0,test_set$outputType)
cm
cm['TRUE', 1]
cm
cm <- table(y_pred>0,test_set$outputType)
cm
success <- cm['TRUE', 2] + cm['FALSE', 1]
accuracy <- success/nrow(test_set) * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 3)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
cm <- table(y_pred>0,test_set$outputType)
cm
success <- cm['TRUE', 2] + cm['FALSE', 1]
accuracy <- success/nrow(test_set) * 100
accuracy
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-no_observation],
y = training_set$outputType,
ntree = 3)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
cm <- table(y_pred>0,test_set$outputType)
cm
success <- cm['TRUE', 2] + cm['FALSE', 1]
accuracy <- success/nrow(test_set) * 100
accuracy
NOWARNING
#library(readtext)
#library(dplyr)
# install.packages("readtext")
#install.packages("wordcloud")
library(wordcloud)
library(dplyr)
library(readtext)
library(stringr)
dir="C:/Users/Charls/Documents/CunyMSDS/607-Data Acquiction/project-4/dataset/spam/"
filename = list.files(dir)
# get_email_body <- function(email){
#   email_body <- str_split(email,"\n\n") %>% lapply('[[',2) %>% unlist()
#   return(email_body)
# }
get_email_body <- function(emailContent){
msge <- str_split(emailContent,"\n\n") %>% unlist()
body <- paste(msge[2:length(msge)], collapse=' ' )
return(body)
}
#  filepath = "C:/Users/Charls/Documents/CunyMSDS/607-Data Acquiction/project-4/dataset/spam/00001.7848dde101aa985090474a91ec93fcf0"
#
# emailContent1 <-readtext(filepath)
# # email_body <- str_split(emailContent1,"\n\n") unlist()
#
# msg <- get_email_body(emailContent1)
#   msg <- gsub("<.*?>", " ", msg)
# msg
msgContent<-NA
for(i in 1:length(filename))
{
filepath<-paste0(dir,filename[i])
emailContent <-readtext(filepath)
msg <- get_email_body(emailContent)
msg <- gsub("<.*?>", " ", msg)
eachMsg<- list(paste(msg, collapse="\n"))
msgContent = c(msgContent,eachMsg)
}
spam<-data.frame()
spam<-as.data.frame(unlist(msgContent),stringsAsFactors = FALSE)
spam$class<-1
colnames(spam)<-c("msg","class")
head(spam)
suppressWarnings(expr)
#library(readtext)
#library(dplyr)
# install.packages("readtext")
#install.packages("wordcloud")
library(wordcloud)
library(dplyr)
library(readtext)
library(stringr)
dir="C:/Users/Charls/Documents/CunyMSDS/607-Data Acquiction/project-4/dataset/spam/"
filename = list.files(dir)
# get_email_body <- function(email){
#   email_body <- str_split(email,"\n\n") %>% lapply('[[',2) %>% unlist()
#   return(email_body)
# }
get_email_body <- function(emailContent){
msge <- str_split(emailContent,"\n\n") %>% unlist()
body <- paste(msge[2:length(msge)], collapse=' ' )
return(body)
}
#  filepath = "C:/Users/Charls/Documents/CunyMSDS/607-Data Acquiction/project-4/dataset/spam/00001.7848dde101aa985090474a91ec93fcf0"
#
# emailContent1 <-readtext(filepath)
# # email_body <- str_split(emailContent1,"\n\n") unlist()
#
# msg <- get_email_body(emailContent1)
#   msg <- gsub("<.*?>", " ", msg)
# msg
msgContent<-NA
for(i in 1:length(filename))
{
filepath<-paste0(dir,filename[i])
emailContent <-readtext(filepath)
msg <- get_email_body(emailContent)
msg <- gsub("<.*?>", " ", msg)
eachMsg<- list(paste(msg, collapse="\n"))
msgContent = c(msgContent,eachMsg)
}
spam<-data.frame()
spam<-as.data.frame(unlist(msgContent),stringsAsFactors = FALSE)
spam$class<-1
colnames(spam)<-c("msg","class")
head(spam)
#library(readtext)
#library(dplyr)
# install.packages("readtext")
#install.packages("wordcloud")
library(RODBC)
install.packages("RODBC")
library(RODBC)
suppressWarnings(expr)
knitr::opts_chunk$set(echo = TRUE)
# Commented out the library installation lines.
#library(readtext)
#library(dplyr)
# install.packages("readtext")
#install.packages("wordcloud")
#install.packages("RODBC")
library(RODBC)
library(wordcloud)
library(dplyr)
library(readtext)
library(stringr)
spam_word_frequency <- colSums(spamDF)
spam_word_frequency <- sort(spam_word_frequency, decreasing = TRUE)
spam_word_frequency[1:20]
spam_words <- names(spam_word_frequency)
wordcloud(spam_words[1:50], spam_word_frequency[1:50])
ham_word_frequency <- colSums(hamDF)
ham_word_frequency <- sort(ham_word_frequency, decreasing = TRUE)
ham_word_frequency[1:20]
ham_words <- names(ham_word_frequency)
wordcloud(ham_words[1:50], ham_word_frequency[1:50])
shuffledDF <- dataset[sample(1:nrow(dataset)),]
nrow(shuffledDF)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-no_observation])
# Making the Confusion Matrix
cm <- table(y_pred>0,test_set$outputType)
cm
success <- cm['TRUE', 2] + cm['FALSE', 1]
accuracy <- success/nrow(test_set) * 100
accuracy
setwd("~/CunyMSDS/607-Data Acquiction/week10")
